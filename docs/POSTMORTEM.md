# Chart Evaluation Postmortem Template

## Project Overview
**Evaluation Date:** [DATE]  
**Models Evaluated:** Claude Sonnet 4.5, GPT-5, Gemini 2.5 Pro  
**Charts Evaluated:** 10 diverse business charts  
**Total Questions:** [NUMBER]  
**Total Cost:** $[AMOUNT]  

## Key Findings

### Overall Performance
- **Best Performing Model:** [MODEL NAME] with [ACCURACY]% accuracy
- **Most Cost-Effective Model:** [MODEL NAME] at $[COST] per question
- **Fastest Model:** [MODEL NAME] with [LATENCY]s average response time

### Accuracy by Tier
- **Tier 1 (Factual):** [MODEL] - [ACCURACY]%
- **Tier 2 (Pattern):** [MODEL] - [ACCURACY]%

### Cost Analysis
- **Total Evaluation Cost:** $[TOTAL]
- **Cost per Question:** $[AVERAGE]
- **Budget Utilization:** [PERCENTAGE]%

## Model-Specific Analysis

### Claude Sonnet 4.5
**Strengths:**
- [List key strengths observed]

**Weaknesses:**
- [List areas for improvement]

**Error Patterns:**
- [Describe common error types]

**Cost Performance:**
- Total cost: $[AMOUNT]
- Cost per question: $[AMOUNT]

### GPT-5
**Strengths:**
- [List key strengths observed]

**Weaknesses:**
- [List areas for improvement]

**Error Patterns:**
- [Describe common error types]

**Cost Performance:**
- Total cost: $[AMOUNT]
- Cost per question: $[AMOUNT]

### Gemini 2.5 Pro
**Strengths:**
- [List key strengths observed]

**Weaknesses:**
- [List areas for improvement]

**Error Patterns:**
- [Describe common error types]

**Cost Performance:**
- Total cost: $[AMOUNT]
- Cost per question: $[AMOUNT]

## Error Taxonomy Analysis

### Number Hallucinations
- **Most Prone Model:** [MODEL NAME] ([COUNT] occurrences)
- **Common Patterns:** [Describe patterns]
- **Impact:** [Describe impact on accuracy]

### Axis Errors
- **Most Prone Model:** [MODEL NAME] ([COUNT] occurrences)
- **Common Patterns:** [Describe patterns]
- **Impact:** [Describe impact on accuracy]

### Trend Reversals
- **Most Prone Model:** [MODEL NAME] ([COUNT] occurrences)
- **Common Patterns:** [Describe patterns]
- **Impact:** [Describe impact on accuracy]

### Overgeneralization
- **Most Prone Model:** [MODEL NAME] ([COUNT] occurrences)
- **Common Patterns:** [Describe patterns]
- **Impact:** [Describe impact on accuracy]

## Chart Type Performance

### Business Charts
- **Best Model:** [MODEL NAME]
- **Average Score:** [SCORE]
- **Common Challenges:** [List challenges]

### Tech/Product Charts
- **Best Model:** [MODEL NAME]
- **Average Score:** [SCORE]
- **Common Challenges:** [List challenges]

### Financial Charts
- **Best Model:** [MODEL NAME]
- **Average Score:** [SCORE]
- **Common Challenges:** [List challenges]

### Edge Cases
- **Best Model:** [MODEL NAME]
- **Average Score:** [SCORE]
- **Common Challenges:** [List challenges]

## Difficulty Scaling Analysis

### Easy Questions
- **Best Model:** [MODEL NAME] ([ACCURACY]%)
- **Performance Gap:** [Describe differences between models]

### Medium Questions
- **Best Model:** [MODEL NAME] ([ACCURACY]%)
- **Performance Gap:** [Describe differences between models]

### Hard Questions
- **Best Model:** [MODEL NAME] ([ACCURACY]%)
- **Performance Gap:** [Describe differences between models]

## Cost-Performance Trade-offs

### Cost Efficiency Ranking
1. **[MODEL NAME]** - [EFFICIENCY] score/$
2. **[MODEL NAME]** - [EFFICIENCY] score/$
3. **[MODEL NAME]** - [EFFICIENCY] score/$

### Speed Efficiency Ranking
1. **[MODEL NAME]** - [EFFICIENCY] score/s
2. **[MODEL NAME]** - [EFFICIENCY] score/s
3. **[MODEL NAME]** - [EFFICIENCY] score/s

## Unexpected Findings

### Surprising Results
- [Describe unexpected findings]
- [Explain potential reasons]

### Model Behaviors
- [Describe interesting model behaviors]
- [Note any anomalies]

## Technical Issues

### API Reliability
- **Claude:** [Describe any issues]
- **GPT-5:** [Describe any issues]
- **Gemini:** [Describe any issues]

### Evaluation Pipeline
- **Issues Encountered:** [List technical issues]
- **Resolutions:** [Describe how issues were resolved]

## Recommendations

### For Production Use
- **High Accuracy Requirements:** Use [MODEL NAME] for [REASON]
- **Cost-Sensitive Applications:** Use [MODEL NAME] for [REASON]
- **Real-time Applications:** Use [MODEL NAME] for [REASON]

### For Future Evaluations
- **Chart Types to Add:** [List suggestions]
- **Question Types to Expand:** [List suggestions]
- **Evaluation Improvements:** [List suggestions]

### For Model Selection
- **Best Overall:** [MODEL NAME] - [REASON]
- **Best Value:** [MODEL NAME] - [REASON]
- **Most Reliable:** [MODEL NAME] - [REASON]

## Lessons Learned

### What Worked Well
- [List successful aspects of the evaluation]
- [Note effective methodologies]

### What Could Be Improved
- [List areas for improvement]
- [Suggest modifications]

### Key Insights
- [List major insights gained]
- [Note implications for future work]

## Data Quality Assessment

### Ground Truth Quality
- **Chart Generation:** [Assess quality]
- **Question Design:** [Assess quality]
- **Answer Accuracy:** [Assess quality]

### Evaluation Reliability
- **Scoring Consistency:** [Assess reliability]
- **Error Detection:** [Assess accuracy]
- **Cost Tracking:** [Assess accuracy]

## Next Steps

### Immediate Actions
- [List immediate follow-up actions]
- [Note any urgent issues to address]

### Future Research
- [List research directions]
- [Note areas for deeper investigation]

### System Improvements
- [List system enhancements]
- [Note infrastructure improvements]

## Appendices

### A. Detailed Statistics
[Include detailed statistical analysis]

### B. Sample Responses
[Include examples of good and poor responses]

### C. Error Examples
[Include examples of each error type]

### D. Cost Breakdown
[Include detailed cost analysis]

---
 
**Review Date:** [DATE]  
**Next Evaluation:** [DATE]
